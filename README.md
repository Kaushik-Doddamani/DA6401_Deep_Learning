# DA6401_Deep_Learning
Source code for assignments of course DA6401

Name: Kaushik Ningappa Doddamani

## Optimizers and Loss Functions

Optimizers implemented:
- SGD - Stochastic Gradient Descent
- Momentum - Momentum SGD
- NAG - Nesterov Accelerated Gradient (optimized version)
- RMSProp - Root Mean Square Propagation
- Adam - Adaptive Moment Estimation
- Nadam - Nesterov Adaptive Moment Estimation

Loss functions implemented:
- Cross Entropy
- Mean Squared Error


## Dataset

The dataset is from Fashion MNIST available in keras in the keras.datasets module.

# Solutions:

